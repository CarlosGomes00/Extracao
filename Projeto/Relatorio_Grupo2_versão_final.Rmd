---
title: "**Trabalho Prático de Extração de Conhecimento de Dados Biológicos**"
date: "`r Sys.Date()`"
author: "Carlos Gomes (PG51681), Laís Carvalho (PG52536), Rita Nóbrega (PG46733)"
output: 
  html_document:
    toc: yes
    toc_depth: 2
    toc_float: yes
    theme: spacelab
    number_sections: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{=html}
<style>
  body {text-align:justify}
</style>
```

------------------------------------------------------------------------

# **Contextualização**

O conjunto de dados selecionados para este trabalho foram retirados de um estudo cohort com 672 amostras recolhidas através de biopsias a 562 pacientes com Leucemia Mielóide Aguda (LMA)[^1]. Com o objetivo de correlacionar a sensibilidade e resistência de grupos de pacientes com LMA a tratamentos já existentes com a ocorrência de mutações, foram realizadas anotações clínicas detalhadas, estudos genómicos e transcriptómicos (com a sequenciação do exoma (622 amostras) e do RNA (451 amostras)), assim como testes *ex vivo* de sensibilidade a compostos. Os dados e estudo original podem ser consultados através do Genomic Data Commons (GDC)[^2].

[^1]: (Tyner *et al*., 2018)

[^2]: <https://www.cbioportal.org/study/summary?id=aml_ohsu_2018>

Este trabalho tem como objetivo analisar os dados de expressão de pacientes com AML, comparando os seus dados transcriptómicos de acordo com o sexo, tipo de amostra e tratamentos cumulativos dados aos pacientes, com vista a obter informações sobre genes possivelmente expressos diferencialmente e/ou enriquecidos, que tenham um papel importante no tratamento da doença e na sobrevivência dos pacientes.

```{r Import dos packages, echo=FALSE}
library(summarytools)
library(car)
library(readr)
library(dplyr)
library(ggplot2)
library(gplots)
library(ggpubr)
library(genefilter)
library(edgeR)
library(limma)
library(ggfortify)
library(scatterplot3d)
library(factoextra)
library(MASS)
library(caret)
library(randomForest)
library(party)
library(e1071)
```

# **Datasets**

## *Transferência e leitura dos datastes*

Depois de importar as bibliotecas necessárias, começamos por **associar** os datasets presentes no repositório online [^3] a uma **variável**.

[^3]: <https://github.com/lais-carvalho/Trabalho-pratico/tree/main/Dados>

```{r Leitura dos ficheiros}

RNA_cpm = read.table("data_mrna_seq_cpm.txt", header = T, sep = '\t')   

data_patient = read.table("data_clinical_patient.txt", header = T, sep = '\t')

data_sample = read_tsv("data_clinical_sample.txt", na = "", show_col_types = FALSE)

data_mutations = read.table("data_mutations.txt", header = T, sep = '\t')

```

## *Pré-processamento dos dados* {.tabset}

### RNA_cpm

Os nossos dados de transcriptómica já se encontram normalizados através do método Trimmed Mean of M caling (TMM) que serve para corrigir diferenças sistemáticas na composição das bibliotecas de RNA entre amostras (sendo uma normalização do tamanho da biblioteca e não dos dados em si), ajudando a reduzir a variabilidade técnica entre amostras.
Após esta normalização TMM, as contagens foram convertidos para CPM (Counts per million), uma medida comum em análise de expressão génica que normaliza as contagens tendo em consideração as diferenças na profundidade de sequenciação entre as amostras.

Começámos por verificar alguns aspetos relativamente ao dataset para perceber que tipo de preparação/tratamento os dados necessitavam.

```{r Verificar a estrutura dos dados}

class(RNA_cpm)

head(unlist(lapply(RNA_cpm,class)) )

dim(RNA_cpm)

head(colnames(RNA_cpm))

head(rownames(RNA_cpm))

```

Com o código acima é possível perceber:

-   **class(RNA_cpm)** -\> Classe do dataset, dataframe neste caso;

-   **unlist(lapply(RNA_cpm,class))** -\> Classe de cada coluna do dataframe

-   **dim(RNA_cpm)** -\> Dimensão do dataframe;

-   **colnames(RNA_cpm)** e **head(rownames(RNA_cpm))** -\> Verificar se o nome dos genes se está associado às linhas, e o nome das amostras às colunas.

Verificámos assim que o dataset é um **dataframe** com uma dimensão de 22843 linhas e 453 colunas. As linhas são referentes a genes (não estando o nomes destes ainda associados a cada linha) enquanto que as colunas corresppondem às amostras. Dado que as duas primeiras colunas são referentes ao nome e ID dos genes, a dimensão do dataset está como esperado apresentando **22843 genes** e **451 amostras**.

Quando tentámos associar o nome dos genes à coluna, reparámos que devido há existência de genes duplicados não o conseguimos fazer. Assim, procedemos à verificação destes duplicados.  

```{r Remover duplicados}

which(duplicated(RNA_cpm[,1]))

RNA_cpm[which(duplicated(RNA_cpm[,1])),1]

which(RNA_cpm == 'BTBD8', arr.ind = T)

RNA_cpm[which(duplicated(RNA_cpm[,1])),1] = paste(RNA_cpm[which(duplicated(RNA_cpm[,1])),1], "_duplicado", sep = "")

which(duplicated(RNA_cpm[,1]))
      
RNA_cpm[13532, 1]

```

O código utilizado serviu para:

-   **(which(duplicated(RNA_cpm[,1])))** -\> Saber quantos genes têm o nome repetido (6 nomes duplicados neste caso);

-   **RNA_cpm[which(duplicated(RNA_cpm[,1])),1]** -\> Obter o nome dos genes duplicados;

-   **which(RNA_cpm == 'BTBD8', arr.ind = T)** -\> Confirmar se o nome está duplicado;

Nesta fase, e através de verificação manual, percebemos que o nome é de facto igual, no entanto os valores associados são diferentes.

Optamos então por adicionar "\_duplicado" para os distinguir.

-   \*\*RNA_cpm[which(duplicated(RNA_cpm[,1])),1] = paste(RNA_cpm[which(duplicated(RNA_cpm[,1])),1], "\_duplicado", sep = "")\*\* -\> Adiciona o "duplicado";

-   **which(duplicated(RNA_cpm[,1]))** -\> Retorna as posições das linhas duplicadas da primeira coluna;

-   **RNA_cpm[13532, 1]** -\> Retorna o valor na linha 13532 e coluna 1.

Assim, já é possível associar o nome dos genes às linhas, corretamente:

```{r Associar os nomes}

rownames(RNA_cpm) = RNA_cpm[, 1]

head(rownames(RNA_cpm))

```

-   **rownames(RNA_cpm) = RNA_cpm[, 1]** -\> Transformar os valores da primeira coluna, no nome das linhas;

-   **head(rownames(RNA_cpm))** -\> para Verificar se não ocorreu nenhum erro no comando anterior e que o nome dos genes está associado às linhas;

De seguida, continuamos com o pré-processamento dos dados, verificando se existem valores omissos.

```{r Valores Omissos}
any(is.na(RNA_cpm))

RNA_cpm$Entrez_Gene_Id <- NULL

any(is.na(RNA_cpm))

```

-   **any(is.na(RNA_cpm))** -\> Ver se há missing values

-   **RNA_cpm\$Entrez_Gene_Id \<- NULL** -\> Eliminar a coluna com missing values

-   **any(is.na(RNA_cpm))** -\> Verificar outra vez se há missing values

Os valores omissos que existiam no dataframe estavam todos presentes na mesma coluna ('Entrez_Gene_Id"), por isso depois da sua eliminação, já não existem NAs.


### Metadados {.tabset}

#### data_sample

Começámos por verificar alguns aspetos relativos ao dataset:

```{r Formato do dataset}
class(data_sample) 

data_sample = as.data.frame(data_sample)

class(data_sample)

data_sample = data_sample[-c(1:3),]

colnames(data_sample) = data_sample[1,]

data_sample = data_sample[-1,]

str(data_sample)

```

-   **class(data_sample)** -\> Retorna a classe do dataset;

-   **data_sample = as.data.frame(data_sample)** -\> Converte o dataset todo num dataframe;

-   **str(data_sample)** -\> Fornece uma descrição sobre a estrutura do dataframe.

Havia vários formatos neste dataset, então decidimos estabelecer tudo como dataframe. Verificamos também que a classe de todas as colunas correspondem a um "character", algo que teremos em atenção mais à frente.

Depois de retirarmos as 4 primeiras linhas que não continham informações de metadados, podemos ver a dimensão do dataframe:

```{r Dimensão do dataframe}

dim(data_sample)

```

-   **dim(data_sample)** -\> Retorna um vetor com o número de linhas e o número de colunas no datafrmae;

O dataframe possui **672** linhas correspondentes a **amostras**, como era esperado, e **75** colunas correspondentes a **variáveis**.


Associámos também cada linha ao ID de uma amostra:

```{r Associar as linhas}
data_sample$SAMPLE_ID = gsub("-", ".", data_sample$SAMPLE_ID) 

row.names(data_sample) = data_sample$SAMPLE_ID

head(row.names(data_sample))

```

-   **row.names(data_sample) = data_sample$SAMPLE_ID** -\> Associa os IDs das amostras com o nome das linhas do dataframe;

-   **row.names(data_sample)** -\> Imprime o nome das linhas do dataframe;

-   **row.names(data_sample) = gsub("-", ".", row.names(data_sample))** -\> Substitui todos os hifens nas linhas por pontos;

-   **data_sample = data_sample[,-2]** -\> Remove a segunda coluna do dataframe.


Para além de fazermos a associação, removemos ainda a segunda coluna do dataframe e ainda substituimos os hifens das linhas por pontos, de forma a padronizar a formatação dos nomes das linhas.

Depois, verificamos se existem duplicados no ID dos pacientes e no ID das amostras:

```{r Verificar duplicados}

any(duplicated(data_sample$PATIENT_ID))

any(duplicated(data_sample$SAMPLE_ID))

```

-   **any(duplicated(data_sample$PATIENT_ID))** -\> Verifica se existe algum valor duplicado na coluna "PATIENT_ID";

-   **any(duplicated(data_sample$SAMPLE_ID))** -\> Verifica se existe algum valor duplicado na coluna "SAMPLE_ID".

Percebemos que existem IDs dos pacientes duplicados, o que demonstra que várias amostras podem ter sido retiradas do mesmo paciente.

Além disso, não existem amostras duplicadas, tal como era previsto.

```{r Tipo de dados dos metadados das amostras}
fatores_sample_data = c(3:25, 27:29, 46, 49, 52, 54, 57:69, 71:74)
for (coluna in fatores_sample_data) {
  data_sample[[coluna]] = as.factor(data_sample[[coluna]])
}

colunas_numericas_sample_data = c(26, 30:45, 47, 48, 50, 51, 53, 55, 56, 70, 75)
for (coluna in colunas_numericas_sample_data) {
  data_sample[[coluna]] = as.numeric(data_sample[[coluna]])
}

unlist(lapply(data_sample,class))
```

Nem todas as amostras foram utilizadas para o processo de análise de RNAseq. Existem dois campos nos metadados: RNA sequenced e RNA seq analysis.

Através da tabela de dados de RNA-seq, sabemos que 451 amostras foram analisadas.


```{r Filtração dos dados}

fraqRNAseq = table(data_sample$RNA_SEQ_ANALYSIS)

pie(fraqRNAseq, main = "RNA-Seq analysis?")

```

-   **table(data_sample$RNA_SEQ_ANALYSIS)** -\> Conta a frequência de cada categoria presente na coluna "RNA_SEQ_ANALYSIS";

-   **pie(table(data_sample$RNA_SEQ_ANALYSIS), main = "RNA-Seq analysis?")** -\> Cria um pie chart que mostra a distribuição dos valores da coluna;

```{r}
sample_data_rna = data_sample[data_sample$RNA_SEQ_ANALYSIS == 'Yes',]

dim(sample_data_rna)

sum(row.names(sample_data_rna) %in% colnames(RNA_cpm))
```

-   **sample_data_rna = data_sample[data_sample$RNA_SEQ_ANALYSIS == 'Yes',]** -\> Filtra o dataframe para icluir apenas os valores que correspondem a "YES";

-   **sum(row.names(sample_data_rna) %in% colnames(RNA_cpm))** -\> Calcula o número de linhas em "sample_data_rna" que estão presentes nas colunas do "RNA_cpm".

O código em cima serviu como filtro para perceber que dados de RNA-seq utilizar nas análises posteriores, garantindo que coincidem com os dados do dataset "RNA_cpm".

#### data_patient

Começámos por verificar alguns aspetos relativos ao dataset:

```{r Classes de data_patient}

class(data_patient)

dim(data_patient)

unlist(lapply(data_patient,class))

head(row.names(data_patient))

row.names(data_patient) <- data_patient$PATIENT_ID

head(row.names(data_patient))

```

-   **unlist(lapply(data_patient,class)))** -\> Aplica a função class a cada coluna do dataframe usando lapply, em seguida, unlist é usada para converter a lista resultante num vetor;

-   **row.names(data_patient) <- data_patient$PATIENT_ID** -\> Associa os IDs dos pacientes como os nomes das linhas do dataframe;

-   **data_patient <- data_patient[,-1]** -\> Seleciona todas as linhas do dataframe, com exceção da primeira.

O dataset corresponde a um dataframe com 562 amostras e 22 variáveis. As colunas possuem três tipos de estrutura de dados ("character", "integer" e "numeric"), mas iremos transformar em fatores as variáveis não numéricas.

```{r Tipo de dados - Metadados do paciente}
fatores_patient = c(3, 2, 5:19, 21:22)
for (coluna in fatores_patient) {
  data_patient[[coluna]] = as.factor(data_patient[[coluna]])
}

colunas_numericas_patient = c(4,20)
for (coluna in colunas_numericas_patient) {
  data_patient[[coluna]] = as.numeric(data_patient[[coluna]])
}

unlist(lapply(data_patient,class))
```

 
Depois vamos ver se exitem NAs.

```{r Verificação de NAs}

sum(is.na(data_patient))

```

-   **sum(is.na(data_patient))** -\> Calcula a soma de todos os NAs.


Existem 71 NAs, mas em metadados é normal e por isso iremos mantê-los por agora.

Por fim, realizamos a criação de um subset, tal como fizemos com os metadados anteriores, para garantir um dataframe com dados de pacientes presentes em "sample_data_rna", garantindo assim uma análise aos pacientes para os quais possuimos dados relevantes.

```{r Filtração dos dados p}
patient_data_rna <- data_patient %>% filter(row.names(data_patient) %in% sample_data_rna$PATIENT_ID)
```

-   **patient_data_rna = data_patient %>% filter(data_patient$PATIENT_ID %in% sample_data_rna$PATIENT_ID)** -\> Cria um novo dataframe ("patient_data_rna") filtrando o dataframe ("data_patient") com base nos IDs dos pacientes presentes no dataframe.

### data_mutations

Começámos por verificar alguns aspetos relativos ao dataset:

```{r Classes de data_mutations}

class(data_mutations) 

dim(data_mutations)

unlist(lapply(data_mutations,class))

head(row.names(data_mutations))

row.names(data_mutations) = make.unique(data_mutations$Hugo_Symbol) 

head(row.names(data_mutations))

sum(is.na(data_mutations))

```

-   **unlist(lapply(data_mutations,class))** -\> Aplica a função class a cada coluna do dataframe;


-   **row.names(data_mutations) = make.unique(data_mutations$Hugo_Symbol) ** -\> Associa os dados presentes na coluna "Hugo_Symbol" com os nomes das linhas nos dataframes, e para evitar duplicados, adiciona um sufixo.


É possível ver que temos um dataframe com 9910 linhas e 64 colunas. 
No dataframe existem também um número bastante elevados de NAs, 155469.

De seguida, vamos verificar a estrutura interna dos dados de cada coluna:

```{r Preparação dos dados}

unlist(lapply(data_mutations,class))

colunas_fator_mut <- c(1, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,29,30,31,32, 33, 45, 47, 48, 51, 57, 60, 64)

colunas_numericas_mut <- c(34,35,36,37,43, 54, 58, 63)

colunas_char_mut <- c(2,6,7)

data_mutations[, colunas_fator_mut]<- lapply(data_mutations[, colunas_fator_mut], as.factor)

data_mutations[, colunas_numericas_mut]<- lapply(data_mutations[, colunas_numericas_mut], as.numeric)

data_mutations[, colunas_char_mut]<- lapply(data_mutations[, colunas_char_mut], as.character)
```

-   **colunas_fator <- c(1, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,29,30,31,32, 33, 45, 47, 48, 51, 57, 60, 64)** -\> Cria um vetor com colunas para as transformar em fatores;

-   **colunas_numericas <- c(34,35,36,37,43, 54, 58, 63)** -\> Cria um vetor com colunas para as transformar em valores numéricos;

-   **colunas_char <- c(2,6,7)** -\> Cria um vetor com colunas para as transformar em caracteres;

-   **data_mutations[, colunas_fator]<- lapply(data_mutations[, colunas_fator], as.factor)** -\> Transforma as colunas selecionadas anteriormente em fatores;

-   **data_mutations[, colunas_numericas]<- lapply(data_mutations[, colunas_numericas], as.numeric)** -\> Transforma as colunas selecionadas anteriormente em numéricos;

-   **data_mutations[, colunas_char]<- lapply(data_mutations[, colunas_char], as.character)** -\>Transforma as colunas selecionadas anteriormente em caracteres;


Ao analisar a estrutura de dados de cada coluna, percebemos que era necessário transformar alguns dos dados para facilitar a sua manipulação:

- os valores das colunas presentes no vetor associado a "colunas_fator" foram transformadas em fatores;

- os valores das colunas presentes no vetor associado a "colunas_numericas" foram transformados em valores numéricos;

- os valores das colunas presentes no vetor associado a "colunas_char" foram transformados em caracteres. 

Por fim, procedemos à criação de um subset que contém apenas as linhas de "data_mutations" correspondentes às mutações que estão presentes nos dados de "RNA_cpm" para restringir a análise apenas às mutações para as quais temos dados de expressão gênica.

```{r Filtragem dos dados m}
mutations_subset = data_mutations %>% filter(data_mutations$Hugo_Symbol %in% RNA_cpm$Hugo_Symbol)

head(mutations_subset)
```

# **Sumarização dos dados**

Criação de dataframe com todos os metadados tendo em conta o ID dos Pacientes associados a cada amostra que tiveram o RNA sequenciado para facilitar o tratamento de metadados.

```{r}
metadados = merge(sample_data_rna, patient_data_rna, by='PATIENT_ID', all=T)

dim(metadados)
```
Vamos retirar dos metadados as variáveis que não vamos usar na análise, deixando apenas no dataframe as variáveis de interesse.
```{r}
colnames(metadados)
```

```{r}
row.names(metadados) = metadados$SAMPLE_ID

variaveis_interessantes = c(1:4, 6:10, 18:29, 52, 70, 73, 76:78, 90:95)

metadados = metadados[, variaveis_interessantes]

```


```{r Sumariazação metadados}
print(dfSummary(metadados, style = 'grid', graph.magnif = 1, valid.col = FALSE,
                max.distinct.values = 5, col.widths = c(100, 200, 200, 350, 500, 250),
                dfSummary.silent  = TRUE, headings = FALSE, justify = 'l')
      , method = 'render', max.tbl.height = 500)

```

## mutations_subset

```{r}
colunas_relevantes = c("Chromosome", "Start_Position", "End_Position", "Strand", "Variant_Classification", "Variant_Type", "Tumor_Seq_Allele1", "Tumor_Seq_Allele2", "Validation_Status", "Mutation_Status", "impact", "n_vaf")

relev_data_mutations = mutations_subset[, colunas_relevantes]
```

```{r Sumarização mutations_subset}

print(dfSummary(relev_data_mutations, style = 'grid', graph.magnif = 1, valid.col = FALSE,
                max.distinct.values = 5, col.widths = c(100, 200, 200, 350, 500, 250),
                dfSummary.silent  = TRUE, headings = FALSE, justify = 'l')
      , method = 'render', max.tbl.height = 500)

```

# **Análise exploratória**

## Metadados dos pacientes:
Considerando variáveis relevantes:

```{r}

boxplot(AGE_AT_DIAGNOSIS ~ OS_STATUS, data = metadados, main = "Idade aquando do diagnostico vs Estado", xlab = "Estado", ylab = "Idade (anos)", col = c("lightblue", "lightgreen", "grey"), names = c("Unknown", "0:LIVING", "1:DECEASED"))

```

O código em cima cria um boxplot que compara as distribuições das idades aquando do diagnóstico entre os diferentes estados de sobrevida. É possível observar que a idade com que foram diagnosticados não parece ter uma influência ou associação significativa com a sobrevivência do paciente, embora a idade aquando do diagnóstico seja menor nos pacientes que ainda estão vivos, o que pode ter a ver com o facto da rapidez de diagnóstico estar normalmente associada a uma maior taxa de sobrevivência.

De seguida, decidimos averiguar a distribuição das etnias:

```{r Distibuição de etnias}

valores = table(metadados$ETHNICITY)

nome = c("AdmixedAsian", "AdmixedBlack", "AdmixedWhite", "Asian", "Black", "HispNative", "White")

pie(valores, labels = rep("", length(valores)), col = c("black",3,4,5,6,7,2), main = "Etinias") 
legend("right", legend = nome, bty = "n", cex = 0.8, fill = c("black",3,4,5,6,7,2))
```

Verificámos que as etnias mais representadas neste dataset são "White", "Hispanic Native", "Black" e "Asian" respetivamente.

De seguida, procedemos à comparação da idade de diagnóstico entre os géneros

```{r Idade de Diagnóstico}

boxplot(AGE_AT_DIAGNOSIS ~ SEX, data = metadados, main = "Idade do diagnostico vs gênero", xlab = "Gênero", ylab = "Idade em anos", col = c(2,'lightblue'))

```

No boxplot é possível observar que a idade dos pacientes masculinos, é ligeiramente mais elevada, possuindo limites, quartis e mediana com idades superiores comparativamente aos pacientes femininos. Verifica-se também uma maior presença de outliers nos dados dos pacientes masculinos comparativamente aos femininos.

Finalmente, fizemos uma análise sobre o diagnóstico mais recorrente que revelou ser 'Acute Myeloid Leukaemia (AML) and Related Precursor Neoplasms'.

```{r Diag mais recorrente data_patient}

d = table(metadados$DIAGNOSIS)

d = as.data.frame(d)

indice_maximo <- which.max(d$Freq)

nome_maximo <- d$Var1[indice_maximo]

nome_maximo

```

## Metadados das amostras

```{r}

pie(table(metadados$SAMPLE_SITE), main = "Local de recolha das amostras")

```

O gráfico demonstra como as amostras estão distribuídas pelos locais de recolha. Os locais de recolha de amostra mais frequentes entre os dados analisados são o "Aspirado de Medula Óssea" com pouco mais de 50% das amostras, o "Sangue Periférico" com uma distribuição pouco menor do que 50% das amostras, e a "Leucaferese" com opção menos utilizada. 

Por último verificamos qual o nome do grupo de diagnóstico mais frequente nos dados

```{r Diag mais recorrente data_sample}

x = table(metadados$GROUP)

x = as.data.frame(x)

indice_maximo <- which.max(x$Freq)

nome_maximo <- x$Var1[indice_maximo]

nome_maximo

```



## mutations_subset

```{r}

barplot(table(relev_data_mutations$Chromosome), main = "Cromossomos", col = "4")

pie(table(relev_data_mutations$Variant_Type), main = "Tipo de variação")

```

Com o código em cima, geramos um gráfico de barras que mostra a contagem de ocorrências de cada cromossoma, e um gráfico de pizza para perceber a distribuição dos tipos de variantes no dataframe. 

É possível observar que a variante mais frequente no dataframe é a "SNP", seguida da "INS" e da "DEL".

Depois, verificamos qual a mutação mais comum no Alelo 1 entre as amostras analisadas

```{r Mutação mais comum 1}

mut = table(relev_data_mutations$Tumor_Seq_Allele1)

mut = as.data.frame(mut)

indice_maximo <- which.max(mut$Freq)

nome_maximo <- mut$Var1[indice_maximo]

nome_maximo

```

A mutação mais comum referente ao Alelo 1, é a alteração por Citosinas. Este dado pode ser útil na identificação de uma doença ou de um potêncial alvo terapêutico.


Analisamos ainda qual a mutação mais comum no Alelo 2 entre as amostras analisadas:

```{r Mutação mais comum 2}

mut2 = table(relev_data_mutations$Tumor_Seq_Allele2)

mut2 = as.data.frame(mut2)

indice_maximo <- which.max(mut2$Freq)

nome_maximo <- mut2$Var1[indice_maximo]

nome_maximo # A mutação mais comum é a alteração por T

```

Já no Alelo 2, a mutação mais comum é a alteração por Timina.


# **Análise Univariada**

## Análise com as variáveis dos pacientes

As variáveis analisadas foram: Idade e sexo dos pacientes, teve como objectivo de determinar se os dois grupos de sexo ("Male" e "Female") deferiam quanto as idades. Para fazer esta análise, foi avaliado se os dois diferentes grupos apresentam médias diferentes. 

```{r, warning=FALSE}
table(metadados$SEX) # Confirmação de quantos grupos de sexos há.

# Testar a homogeneidade das variâncias
leveneTest(metadados$AGE_AT_DIAGNOSIS~metadados$SEX) # Não rejeitar a hipótese de que as variâncias dos grupos são iguais. 

# Testar a normalidade dos diferentes grupos
teste_normalidade_masculino=shapiro.test(metadados$AGE_AT_DIAGNOSIS[metadados$SEX == "Male"])
teste_normalidade_feminino=shapiro.test(metadados$AGE_AT_DIAGNOSIS[metadados$SEX == "Female"])
print(teste_normalidade_masculino) # Não normal
print(teste_normalidade_feminino) # Não normal

# Visualização da normalidade com qqPlot
qqPlot(metadados$AGE_AT_DIAGNOSIS[metadados$SEX == "Male"], main = "Q-Q Plot - Masculino", ylab = "Idade")
qqPlot(metadados$AGE_AT_DIAGNOSIS[metadados$SEX == "Female"], main = "Q-Q Plot - Feminino", ylab = "Idade")
```

```{r}
# Normalidade geral das idades
shapiro.test(metadados$AGE_AT_DIAGNOSIS) # Não normal

# Retirada dos NAs:
idades_sem_na <- na.omit(metadados$AGE_AT_DIAGNOSIS)

# Criar gráfico de densidade sem valores ausentes
ggdensity(idades_sem_na,
          main = "Gráfico de densidade para a idade dos pacientes",
          xlab = "Idade dos pacientes")
```

Não pode rejeitar a hipótese nula, nesse caso que as variâncias são homogéneas, e com os gráficos qqPlot e as análises de normalidade, foi possível determinar que as distribuições não são normais, mas considerando um tamanho elevado das amostras, realizamos um t-test e analisamos a relação entre sexo e idade. 

```{r, warning=FALSE}
# T-test
t.test(metadados$AGE_AT_DIAGNOSIS ~ metadados$SEX, na.rm = TRUE)
```

Com base na análise final, é possível concluir que as idades diferem para os grupos "Male" e "Female". Implicando que em análises de expressão com estes diferentes grupos, parte das variações e diferenças podem ser reflexo das diferentes idades.

## Análise de varáveis no metadado de mutações

- "n_vaf" (Frequência do Alelo Variante Normalizado),é a frequência do alelo variante, sendo uma variável numérica.

- Impact: variável que se refere ao efeito ou consequência que uma determinada mutação pode ter em um gene ou em uma função biológica específica. É uma variável nominal.

O objetivo desta comparação é verificar se a frequência do alelo variante é diferente em cada categoria de impacto das mutações. Isso pode ser útil para identificar mutações driver, ou seja, aquelas que contribuem para a progressão e desenvolvimento do câncer.

```{r}
# Avaliar a variável "N_vaf" quanto a presença de NAs e distribuição
sum(is.na(relev_data_mutations$n_vaf))
ggdensity(relev_data_mutations$n_vaf, main = "Distribuição da variável `n_vaf`")

# Avaliação das diferentes classes de impacto
table(relev_data_mutations$impact) # Há 3 classes: "High", "Moderate" e "Modifier"
```

```{r}
# Avaliar a normalidade de n_vaf
qqPlot(relev_data_mutations$n_vaf, ylab = "Frequência de mutções no alelo variente",  main = "qqPlot de VAF normalizado") # não é normal

# Avaliar a homegneidade das variâncias
leveneTest(relev_data_mutations$n_vaf~relev_data_mutations$impact) # as variâncias entre diferentes grupos de impacto não são homogéneas.  

# Teste se as medianas são ou não igaus para os diferentes grupos
res = kruskal.test(relev_data_mutations$n_vaf~relev_data_mutations$impact, data = relev_data_mutations)
res # Não são estatisticamente diferentes
```

Com os resultados obtidos, não é possível rejeitar a hipótese nula que as medianas são iguais, nesse caso significa que não há variações significativas entre as frequências de mutações dos alelos variantes para diferentes grupos de impacto.

## Análise para variáveis das amostras

- "AGE_AT_PROCUREMENT" - Idade dos pacientes na aquisição das amostras.

- "ELN_2017" - variável usada para classificar pacientes com leucemia mieloide aguda (LMA) em diferentes grupo de risco. 

Esta análise tem como objectivo avaliar se a idade tem associação com diferentes grupos de risco.

```{r,warning=FALSE}
# Avaliação das variáveis
table(metadados$ELN_2017) # Há 6 grupos de clssificações de risco
summary(metadados$AGE_AT_PROCUREMENT) # Há um NA.

# Criar o gráfico de dispersão 
ggplot(metadados, aes(x = ELN_2017, y = AGE_AT_PROCUREMENT, color = ELN_2017)) +
  geom_point(size = 3) +  
  labs(x = "Classificação de Risco ELN 2017", y = "Idade na Aquisição", title = "Idade na Aquisição vs. Classificação de Risco ELN 2017") +  
  theme_minimal() +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r}
# Analisando a normalidade e homogeneidade das variâncias:

qqPlot(metadados$AGE_AT_PROCUREMENT, ylab = "idade", main = "Distribuição das idades dos pacientes na recolha das amostras")

shapiro.test(metadados$AGE_AT_PROCUREMENT) # Não é normal

# Análise da variância
leveneTest(AGE_AT_PROCUREMENT ~ ELN_2017, data = metadados) # Homogénea

# ANOVA
anova_result <- aov(AGE_AT_PROCUREMENT ~ ELN_2017, data = metadados)
summary(anova_result)

## Análise por grupo:
tukey_result <- TukeyHSD(anova_result)
print(tukey_result)
```

Considerando um elevado tamanho da amostra, a análise ANOVA foi feita, mesmo sabendo que a variável "AGE_AT_PROCUREMENT" não segue a distribuição normal. É possível concluir que a idade dos pacientes interferem na determinação de dois grupos de risco: "Favoravel" e "Adverse".

A mesma análise foi reproduzida para as classificações de pacientes com leucemia mieloide aguda (LMA) em diferentes grupo de risco definidas em 2008. 

```{r warning=FALSE}
# Avaliação das variáveis
table(metadados$ELN_2008) # Há 6 grupos de clssificações de risco
summary(metadados$AGE_AT_PROCUREMENT) # Há um NA.

# Criar o gráfico de dispersão 
ggplot(metadados, aes(x = ELN_2008, y = AGE_AT_PROCUREMENT, color = ELN_2008)) +
  geom_point(size = 3) +  
  labs(x = "Classificação de Risco ELN 2008", y = "Idade na Aquisição", title = "Idade na Aquisição vs. Classificação de Risco ELN 2008") +  
  theme_minimal() +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
# Análise da variância
leveneTest(AGE_AT_PROCUREMENT ~ ELN_2008, data = metadados) # Levemente não homogénea

# ANOVA
anova_result <- oneway.test(AGE_AT_PROCUREMENT ~ ELN_2008, data = metadados, var.equal = FALSE)
print(anova_result)

## Análise por grupo:
library(PMCMRplus)
# Realizar o teste de Games-Howell
games_howell_test <- gamesHowellTest(AGE_AT_PROCUREMENT ~ ELN_2008, data = metadados)
print(games_howell_test)

```

Diferentemente das classificações de 2017, os dois grupo que apresentaram maior interferência das idades pela classificação de 2008 foram "Favorable" e "Intermediate-I". 

# **Expressão diferencial** {.tabset}

Após uma análise exploratória, concluimos que seria interessante tentar perceber se o sexo, tipo de amostras, o nº e fase dos tratamentos cumulativos, a sobrevivência dos pacientes ou as classificações ELN estavam refletidos nos dados de expressão génica através da análise de expressão diferencial. 

Dado que os nossos dados já sofreram uma normalização TMM e são valores CPM, um pré-processamento equivalente à função <cpm(calcNormFactors(y))> (onde y seria o objeto DGElist que teria as raw counts) normalmente utilizada aquando da análise de expressão diferencial com o package limma.Por isso, iremos fazer uma transformação logaritmica para finalizar o processo de normalização dos dados normalmente feito antes da análise da expressão génica diferencial com o limma.

Dado que os nossos dados já sofreram uma normalização TMM e são valores CPM, um pré-processamento equivalente à função <cpm(calcNormFactors(y))> (onde y seria o objeto DGElist que teria as raw counts) normalmente utilizada aquando da análise de expressão diferencial com o package limma.Por isso, filtramos os genes para que apenas aqueles que tenham pelo menos metade dos pacientes com CPM superior a 1 fossem analisados e depois fizémos uma transformação logaritmica para finalizar o processo de normalização dos dados que é normalmente feito antes da análise da expressão génica diferencial com o limma (pipeline limma-trend).

Na maioria das comparações realizadas não foram encontrados genes diferencialmente expressos. Relativamente ao sexo, em contraste com o que foi encontrado no artigo, não foram encontrados genes diferencialmente expressos, sugerindo que o sexo não é um fator diferencial da expressão dos genes nas amostras destes pacientes.
Na análise da expressão tendo em conta o tipo de amostra retirada (medula óssea, plasma do sangue periférico ou glóbulos brancos através de leucaférese (Leukapheresis), foram detetados alguns genes diferencialmente expressos entre as amostras. Na comparação entre glóbulos brancos e sangue periférico foram encontrados 2 genes subexpressos e 1 sobrexpresso, enquanto que para o contraste entre glóbulos brancos e medula foram encontrados 1 gene subexpresso e 2 sobrexpressos.No vulcano plot é ainda possível ver o nome dos genes diferencialmente expressos, sendo interessante destacar a presença dos mesmos genes na comparação dos genes diferencialmente expressos entre os glóbulos brancos e o plasma do sangue periférico, e entre os glóbulos brancos e a medula óssea, sendo que os genes subexpressos numa comparação são os que estão sobrepxressos na outra. Esta presença comum nas comparações sugere que a razão para a expressão diferencial destes 3 genes está associada aos globulos brancos, dado serem o elemento em comum nas duas comparações feitas. Adicionalmente, também é interessante destacar a função destes genes diferencialmente expressos como, por exemplo, do gene STK24 que codifica uma proteína quinase envolvida na regulação da apoptose e na resposta ao stress celular e do gene CHFR que está envolvido na regulação do ciclo celular e na manutenção da integridade do genoma, sendo que alterações no gene CHFR, assim como na sua expressão, já foram associadas a vários tipos de cancro, incluindo a LMA.
Da mesma forma, alguns genes relacionados com o ciclo celular e resposta ao stress celular (e.g. DNAJC15 e TP73), manutenção da integridade e função celular (e.g. TIMP1, GDP2 e MICAL1) e regulação da expressão génica (e.g. GCFC2), foram encontrados diferencialmente expressos na comparação da fase mais avançada de tratamentos (fase 8) com os outros estados de tratamentos cumulativos e na comparação do nº de tratamentos cumulativos mais elevado com quantidades mais baixas de tratamentos a que os pacientes foram sujeitos. 
Relativamente às classificações ELN, amplamente utilizadas na prática clínica para orientar o tratamento de pacientes com LMA, baseando-se em características genéticas e moleculares, e em fatores clínico, não foram identificados genes diferencialmente expressos entre as classificações ELN de 2008. Todavia ao comparar os genes expressos entre as diferentes classificações ELN de 2017, foram identificados genes diferencialmente expressos entre a classificação Adverso e Favorável e entre a Intermédia e Favorável com o grupo de indívidous cuja classificação não é clara estando entre a Intermédia e Favorável. Os genes diferencialmente expressos (RP11-356, KBTBD7 e KBTBD6) estão relacionados com regulação génica e degradação proteica. 
Em conjunto estes resultados sugerem que os tratamentos para a LMA podem afetar a expressão génica de várias maneiras, incluindo a regulação de genes envolvidos na resposta ao stress celular, na proliferação celular e na diferenciação celular. Adicionalmente, a alteração na expressão destes genes pode estar associada à resposta do paciente ao tratamento ou até indicar a eficácia do tratamento.

```{r preparação dos dados para DE - filtragem}
selected_genes = rowMeans(RNA_cpm[,-1] > 1) > 0.5
RNA_cpm_filtered = RNA_cpm[selected_genes, ]
RNA_cpm_filtered = RNA_cpm_filtered[, -1]

logCPM = log2(RNA_cpm_filtered + 1)
head(logCPM)

y <- DGEList(counts = logCPM, genes = row.names(logCPM))
```
Depois da filtragem, ficámos com 14405 genes para a análise de expressão diferencial.

## Variável: Sexo {.tabset}

```{r Expressão diferencial entre sexos}
table(metadados$SEX)
design_sex = model.matrix(~0+metadados$SEX, data = y$samples)
colnames(design_sex) = levels(metadados$SEX)
row.names(design_sex) = colnames(logCPM)

contrast_sex = makeContrasts(Female - Male, levels = design_sex)
fit_sex = lmFit(logCPM, design_sex)
fit_sex = contrasts.fit(fit_sex, contrast_sex)
fit_sex = eBayes(fit_sex, trend=T)

topTable(fit = fit_sex, genelist = row.names(logCPM))

summa.fit_sex = decideTests(fit_sex)
summary(summa.fit_sex)
```
```{r}
plotMD(fit_sex)
```

## Variável: Local de onde foi retirada a amostra {.tabset}
```{r DE de acordo com o tipo de amostra}
levels(metadados$SAMPLE_SITE) = make.names(levels(metadados$SAMPLE_SITE))

design_site = model.matrix(~0+metadados$SAMPLE_SITE, data = y$samples)
colnames(design_site) = levels(metadados$SAMPLE_SITE)
head(design_site)

contrast_site = makeContrasts( Bone_Leuk = Bone.Marrow.Aspirate - Leukapheresis, 
                           Bone_Blood = Bone.Marrow.Aspirate - Peripheral.Blood,
                           Leuk_Blood = Leukapheresis - Peripheral.Blood,
                           levels=design_site)
fit_site = lmFit(logCPM, design_site)
fit_site = contrasts.fit(fit_site, contrast_site)
fit_site = eBayes(fit_site, trend=T)

topTable(fit = fit_site, genelist = row.names(logCPM))

summa.fit_site = decideTests(fit_site)
summary(summa.fit_site)

```

```{r DE plots - site}
par(mfrow= c(1, 2))
plotMD(fit_site,coef="Leuk_Blood",status=summa.fit_site[,"Leuk_Blood"], values = c(-1, 1), hl.col=c("blue","red"), main = "Leukapheresis vs Periphal Blood")
plotMD(fit_site,coef="Bone_Leuk",status=summa.fit_site[,"Bone_Leuk"], values = c(-1, 1), hl.col=c("blue","red"), main = "Leukapheresis vs Bone Marrow")
```

```{r volcano plots - site}
par(mfrow= c(1, 2))
volcanoplot(fit_site,coef="Leuk_Blood",highlight=3,names=row.names(fit_site), main ="Leukapheresis vs Periphal Blood")
volcanoplot(fit_site,coef="Bone_Leuk",highlight=3,names=row.names(fit_site), main ="Leukapheresis vs Bone Marrow")
```

## Variável: Sobrevivência do paciente {.tabset}
```{r DE de acordo com a sobrevivencia dos pacientes}
table(metadados$OS_STATUS)
metadados$OS_STATUS <- gsub("0:LIVING", "Alive", metadados$OS_STATUS)
metadados$OS_STATUS <- gsub("1:DECEASED", "Deceased", metadados$OS_STATUS)
metadados$OS_STATUS <- as.character(metadados$OS_STATUS)
metadados$OS_STATUS <- ifelse(is.na(metadados$OS_STATUS) | nchar(metadados$OS_STATUS) == 0, "Unknown", metadados$OS_STATUS)
table(metadados$OS_STATUS)
metadados$OS_STATUS <- as.factor(metadados$OS_STATUS)

design_status = model.matrix(~0+metadados$OS_STATUS, data = y$samples)
colnames(design_status) = levels(metadados$OS_STATUS)


contrast_status = makeContrasts(Alive_Deceased = Alive - Deceased,
                                Alive_Unknown = Alive - Unknown,
                                Deceased_Unknown = Deceased - Unknown,
                                levels=design_status)

fit_status = lmFit(y$counts, design_status)
fit_status = contrasts.fit(fit_status, contrast_status)
fit_status = eBayes(fit_status, trend=T)
topTable(fit = fit_status, genelist = y$genes)

summa.fit_status = decideTests(fit_status)
summary(summa.fit_status)
```
```{r}
plotMD(fit_status)
```

## Variável: Estado dos tratamentos cumulativos {.tabset}
```{r DE de acordo com o estado dos tratamentos cumulativos}
table(metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)

metadados$CUMULATIVE_TREATMENT_STAGE_COUNT <- gsub(0, "Zero", metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
metadados$CUMULATIVE_TREATMENT_STAGE_COUNT <- gsub(1, "Um", metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
metadados$CUMULATIVE_TREATMENT_STAGE_COUNT <- gsub(2, "Dois", metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
metadados$CUMULATIVE_TREATMENT_STAGE_COUNT <- gsub(3, "Três", metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
metadados$CUMULATIVE_TREATMENT_STAGE_COUNT <- gsub(4, "Quatro", metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
metadados$CUMULATIVE_TREATMENT_STAGE_COUNT <- gsub(5, "Cinco", metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
metadados$CUMULATIVE_TREATMENT_STAGE_COUNT <- gsub(6, "Seis", metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
metadados$CUMULATIVE_TREATMENT_STAGE_COUNT <- gsub(7, "Sete", metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
metadados$CUMULATIVE_TREATMENT_STAGE_COUNT <- gsub(8, "Oito", metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)

metadados$CUMULATIVE_TREATMENT_STAGE_COUNT = as.factor(metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
table(metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)

design_stage = model.matrix(~0+metadados$CUMULATIVE_TREATMENT_STAGE_COUNT, data = y$samples)
colnames(design_stage) = levels(metadados$CUMULATIVE_TREATMENT_STAGE_COUNT)
head(design_stage)

contrast_stage = makeContrasts('0_1'= Zero - Um, '0_2'= Zero - Dois, '0_3'= Zero - Três, '0_4'= Zero - Quatro, '0_5'= Zero - Cinco, '0_6' = Zero - Seis, '0_7' = Zero - Sete, '0_8' = Zero - Oito, '1_2'= Um - Dois, '1_3'= Um - Três, '1_4'= Um - Quatro, '1_5'= Um - Cinco,
'1_6' = Um - Seis, '1_7' = Um - Sete, '1_8' = Um - Oito, '2_3'= Dois - Três, '2_4'= Dois - Quatro, '2_5'= Dois - Cinco, '2_6' = Dois - Seis, '2_7' = Dois - Sete, '2_8' = Dois - Oito, '3_4'= Três - Quatro, '3_5'= Três - Cinco, '3_6' = Três - Seis, '3_7' = Três - Sete, '3_8' = Três - Oito, '4_5'= Quatro - Cinco, '4_6' = Quatro - Seis, '4_7' = Quatro - Sete, '4_8' = Quatro - Oito, '5_6' = Cinco - Seis, '5_7' = Cinco - Sete, '5_8' = Cinco - Oito,
'6_7' = Seis - Sete, '6_8' = Seis - Oito, '7_8' = Sete - Oito, levels=design_stage)

fit_stage = lmFit(y$counts, design_stage)
fit_stage = contrasts.fit(fit_stage, contrast_stage)
fit_stage = eBayes(fit_stage, trend=T)
topTable(fit = fit_stage, genelist = y$genes)
summa.fit_stage = decideTests(fit_stage)
summary(summa.fit_stage)
```
```{r volcano plots - estado de tratamento}
par(mfrow=c(2, 5))
volcanoplot(fit_stage,coef="2_3",highlight=5, names=row.names(fit_stage), main ="Fases de tratamento: 2 vs 3")
volcanoplot(fit_stage,coef="3_4",highlight=1, names=row.names(fit_stage), main ="Fases de tratamento: 3 vs 4")
volcanoplot(fit_stage,coef="3_7",highlight=3, names=row.names(fit_stage), main ="Fases de tratamento: 3 vs 7")
volcanoplot(fit_stage,coef="0_8",highlight=2, names=row.names(fit_stage), main ="Fases de tratamento: 0 vs 8")
volcanoplot(fit_stage,coef="1_8",highlight=2, names=row.names(fit_stage), main ="Fases de tratamento: 1 vs 8")
volcanoplot(fit_stage,coef="2_8",highlight=4, names=row.names(fit_stage), main ="Fases de tratamento: 2 vs 8")
volcanoplot(fit_stage,coef="3_8",highlight=3, names=row.names(fit_stage), main ="Fases de tratamento: 3 vs 8")
volcanoplot(fit_stage,coef="4_8",highlight=5, names=row.names(fit_stage), main ="Fases de tratamento: 4 vs 8")
volcanoplot(fit_stage,coef="5_8",highlight=2, names=row.names(fit_stage), main ="Fases de tratamento: 5 vs 8")
volcanoplot(fit_stage,coef="6_8",highlight=2, names=row.names(fit_stage), main ="Fases de tratamento: 6 vs 8")
```

## Variável: Nº de tratamentos cumulativos {.tabset}
```{r DE de acordo com o nº de tratamentos}
table(metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)

metadados$CUMULATIVE_TREATMENT_TYPE_COUNT <- gsub(0, "Zero", metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)
metadados$CUMULATIVE_TREATMENT_TYPE_COUNT <- gsub(1, "Um", metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)
metadados$CUMULATIVE_TREATMENT_TYPE_COUNT <- gsub(2, "Dois", metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)
metadados$CUMULATIVE_TREATMENT_TYPE_COUNT <- gsub(3, "Três", metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)
metadados$CUMULATIVE_TREATMENT_TYPE_COUNT <- gsub(4, "Quatro", metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)
metadados$CUMULATIVE_TREATMENT_TYPE_COUNT <- gsub(5, "Cinco", metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)


metadados$CUMULATIVE_TREATMENT_TYPE_COUNT = as.factor(metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)
table(metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)

design_ntreat = model.matrix(~0+metadados$CUMULATIVE_TREATMENT_TYPE_COUNT, data = y$samples)
colnames(design_ntreat) = levels(metadados$CUMULATIVE_TREATMENT_TYPE_COUNT)
head(design_ntreat)

contrast_ntreat = makeContrasts('0_1'= Zero - Um, '0_2'= Zero - Dois, '0_3'= Zero - Três, '0_4'= Zero - Quatro, '0_5'= Zero - Cinco,
                                '1_2'= Um - Dois, '1_3'= Um - Três, '1_4'= Um - Quatro, '1_5'= Um - Cinco,
                                '2_3'= Dois - Três, '2_4'= Dois - Quatro, '2_5'= Dois - Cinco,
                                '3_4'= Três - Quatro, '3_5'= Três - Cinco,
                                '4_5'= Quatro - Cinco,
                                levels=design_ntreat)

fit_ntreat = lmFit(y$counts, design_ntreat)
fit_ntreat = contrasts.fit(fit_ntreat, contrast_ntreat)
fit_ntreat = eBayes(fit_ntreat, trend=T)
topTable(fit = fit_ntreat, genelist = y$genes)
summa.fit_ntreat = decideTests(fit_ntreat)
summary(summa.fit_ntreat)
```

```{r Volcano plots - nº de tratamentos}
par(mfrow=c(2, 2))
volcanoplot(fit_ntreat,coef="0_5",highlight=2, names=row.names(fit_ntreat), main ="Tipos de tratamento: 0 vs 5")
volcanoplot(fit_ntreat,coef="1_5",highlight=4, names=row.names(fit_ntreat), main ="Tipos de tratamento: 1 vs 5")
volcanoplot(fit_ntreat,coef="2_5",highlight=4, names=row.names(fit_ntreat), main ="Tipos de tratamento: 2 vs 5")
volcanoplot(fit_ntreat,coef="3_5",highlight=4, names=row.names(fit_ntreat), main ="Tipos de tratamento: 3 vs 5")
```

## Variável: ELN_2017 {.tabset}

```{r - DE ELN_2017}
table(metadados$ELN_2017)

# Alterar a escrita das classificações para facilitar a análise
metadados$ELN_2017 <- gsub("Favorable or Intermediate", "Favorable_or_Intermediate", metadados$ELN_2017)
metadados$ELN_2017 <- gsub("Intermediate or Adverse", "Intermediate_or_Adverse", metadados$ELN_2017)

metadados$ELN_2017 = as.factor(metadados$ELN_2017)
table(metadados$ELN_2017)

design_ELN2017 =model.matrix(~0+metadados$ELN_2017, data = y$samples)
colnames(design_ELN2017) = levels(metadados$ELN_2017)
head(design_ELN2017)

contrast_ELN2017 = makeContrasts(Adverse_Favorable = Adverse - Favorable,
                                 Adverse_Favorable_or_Intermediate = Adverse - Favorable_or_Intermediate,
                                 Adverse_Intermediate = Adverse - Intermediate,
                                 Adverse_Intermediate_or_Adverse = Adverse - Intermediate_or_Adverse,
                                 Adverse_Unknown = Adverse - Unknown,
                                 Favorable_Favorable_or_Intermediate = Favorable - Favorable_or_Intermediate, 
                                 Favorable_Intermediate = Favorable - Intermediate,
                                 Favorable_Unknown = Favorable - Unknown,
                                 Favorable_or_Intermediate_Intermediate = Favorable_or_Intermediate - Intermediate,
                                 Favorable_or_Intermediate_Unknown = Favorable_or_Intermediate - Unknown,
                                 Intermediate_Intermediate_or_Adverse = Intermediate - Intermediate_or_Adverse,
                                 Intermediate_Unknown = Intermediate - Unknown,
                                 Intermediate_or_Adverse_Unknown = Intermediate_or_Adverse - Unknown,
                                 levels=design_ELN2017)

fit_ELN2017 = lmFit(y$counts, design_ELN2017)
fit_ELN2017 = contrasts.fit(fit_ELN2017, contrast_ELN2017)
fit_ELN2017 = eBayes(fit_ELN2017, trend=T)
topTable(fit = fit_ELN2017, genelist = y$genes)
summa.fit_ELN2017 = decideTests(fit_ELN2017)
summary(summa.fit_ELN2017)
```

```{r}
par(mfrow=c(2, 2))
plotMD(fit_ELN2017,coef="Adverse_Favorable",status=summa.fit_ELN2017[,"Adverse_Favorable"], values = c(-1, 1), hl.col=c("blue","red"), main = "ELN 2017: Adverse vs Favorable")
plotMD(fit_ELN2017,coef="Favorable_Favorable_or_Intermediate",status=summa.fit_ELN2017[,"Favorable_Favorable_or_Intermediate"], values = c(-1, 1), hl.col=c("blue","red"), main = "ELN 2017: Favorable vs Favorable_or_Intermediate")
plotMD(fit_ELN2017,coef="Favorable_or_Intermediate_Intermediate",status=summa.fit_ELN2017[,"Favorable_or_Intermediate_Intermediate"], values = c(-1, 1), hl.col=c("blue","red"), main = "ELN 2017: Favorable_or_Intermediate vs Intermediate")
```

```{r}
par(mfrow= c(1, 3))
volcanoplot(fit_ELN2017,coef="Adverse_Favorable",highlight=1,names=row.names(fit_ELN2017), main ="ELN 2017: Adverse vs Favorable")
volcanoplot(fit_ELN2017,coef="Favorable_Favorable_or_Intermediate",highlight=2,names=row.names(fit_ELN2017), main ="ELN 2017: Favorable vs Favorable or Intermediate")
volcanoplot(fit_ELN2017,coef="Favorable_or_Intermediate_Intermediate",highlight=2,names=row.names(fit_ELN2017), main ="ELN 2017: Favorable or Intermediate vs Intermediate")
```

## Variável: ELN_2008 {.tabset}

```{r DE ELN_2008}
table(metadados$ELN_2008)

# Alterar a escrita das classificações para facilitar a análise e pôr NAs como 'Not Enough information'
metadados$ELN_2008 <- gsub("Not Enough Information", "Not_Enough_Information", metadados$ELN_2008)
metadados$ELN_2008 <- gsub("Intermediate-II", "Intermediate2", metadados$ELN_2008)
metadados$ELN_2008 <- gsub("Intermediate-I", "Intermediate1", metadados$ELN_2008)
metadados$ELN_2008 <- ifelse(is.na(metadados$ELN_2008) | nchar(metadados$ELN_2008) == 0, "Not_Enough_Information", metadados$ELN_2008)

metadados$ELN_2008 = as.factor(metadados$ELN_2008)
table(metadados$ELN_2008)

design_ELN_2008 = model.matrix(~0+metadados$ELN_2008, data = y$samples)
colnames(design_ELN_2008) = levels(metadados$ELN_2008)
head(design_ELN_2008)

contrast_ELN_2008 = makeContrasts(Adverse_Favorable = Adverse - Favorable,
                                  Adverse_IntermediateI = Adverse - Intermediate1,
                                  Adverse_IntermediateII = Adverse - Intermediate2,
                                  Adverse_Unknown = Adverse - Not_Enough_Information,
                                  Favorable_IntermediateI = Favorable - Intermediate1,
                                  Favorable_IntermediateII = Favorable - Intermediate2,
                                  Favorable_Unknown = Favorable - Not_Enough_Information,
                                  IntermediateI_IntermediateII = Intermediate1 - Intermediate2,
                                  IntermediateI_Unknown = Intermediate1 - Not_Enough_Information,
                                  IntermediateII_Unknown = Intermediate2 - Not_Enough_Information,
                                  levels=design_ELN_2008)
dim(design_ELN_2008)

fit_ELN2008 = lmFit(y$counts, design_ELN_2008)
fit_ELN2008 = contrasts.fit(fit_ELN2008, contrast_ELN_2008)
fit_ELN2008 = eBayes(fit_ELN2008, trend=T)
topTable(fit = fit_ELN2008, genelist = y$genes)
summa.fit_ELN2008 = decideTests(fit_ELN2008)
summary(summa.fit_ELN2008)
```

# **Análise não supervisionada**

Com o objetivo de indentificar possíveis padrões ou agrupamentos nos dados de expressão diferencial que nos permitam de alguma forma perver características das amostras ou dos pacientes, especificamente a resposta deste ao tratamento, começamos por uma análise não supervisionada como o clustering hierárquico ou k-means.

Dada a expressão diferencial analisada anteriormente e os resultados obtidos num artigo anterior[^1], optámos por começar por fazer um multidimensional scaling plot para perceber se há alguma distância entre os níveis de expressão de todas as amostras. 

## Classical Multidimensional Scaling

```{r MDS plot}
dist_matrix = dist(t(RNA_cpm_filtered))

mds_result = cmdscale(dist_matrix, k = 2)  # k = 2 para duas dimensões

mds_data = as.data.frame(mds_result)
colnames(mds_data) = c("Dim1", "Dim2")
mds_data$Sample = rownames(mds_data)

mds_data = merge(mds_data, metadados, by.x = "Sample", by.y = "SAMPLE_ID")

ggplot(mds_data, aes(x = Dim1, y = Dim2, label = Sample)) +
  geom_point() +
  geom_text(vjust = 1.5) +
  labs(title = "MDS Plot", x = "Dimension 1", y = "Dimension 2") +
  theme_minimal()
```

Através da interpretação do MDS plot obtido, vemos que apenas aproximadamente 4 amostras cujos níveis de expressão são mais diferentes, estão mais distantes do resto das amostras. Esta semelhança nos níveis de expressão já era expectada dado os resultados da análise de expressão diferencial que não indicaram uma grande quantidade de genes diferencialmente expressos.
Adicionalmente, este resultado também sugere que possivelmente não haverá uma formação de clusteres com estas amostras, porém para o comprovar foi feito o clustering de genes de acordo com algumas variáveis como o sexo, o estado de sobrevivência do paciente e as classificações ENL.

## Clustering de genes de acordo com o sexo dos pacientes

```{r MDS sex}
ggplot(mds_data, aes(x = Dim1, y = Dim2, color = SEX, label = Sample)) +
  geom_point(size = 3) +
  geom_text(vjust = 1.5, size = 3) +
  labs(title = "MDS Plot Colorido por Sexo", x = "Dimension 1", y = "Dimension 2") +
  theme_minimal() +
  scale_color_manual(values = c("red", "blue", "green", "purple"))
```

```{r hierarquico - sexo}
# Preparação dos dados: 
DADOS = t(logCPM) #Transpor os dados
metadados$SEX = as.factor(metadados$SEX)
logCPM_metadados = cbind(DADOS, metadados)

#Clustering
logCPM_metadados.sc = scale(logCPM_metadados[,1:14405])
dist.logCPM_metadados = dist(logCPM_metadados.sc, method = "manhattan")
cl.logCPM_metadados = hclust(dist.logCPM_metadados, method = "average")
my.plot.hc = function(hclust, lab = 1:length(hclust$order), lab.col = rep(1, length(hclust$order)), hang = 0.1, ...)
  
my.plot.hc(cl.logCPM_metadados, lab.col = as.integer(logCPM_metadados$SEX)+1, cex = 0.6)
```

```{r}
logCPM_matrix <- as.matrix(logCPM)

class(logCPM_matrix) <- 'numeric'
max_logCPM_matrix <- apply(logCPM_matrix, 1, max)
min_logCPM_matrix <- apply(logCPM_matrix, 1, min)
vl <-max_logCPM_matrix/min_logCPM_matrix > 2
logCPM_matrix <-logCPM_matrix[vl, ]
logCPM_matrix <-na.exclude(logCPM_matrix)
```

```{r filtrar o top 50 de genes}
expressao <- gsub("\\..*", "", rownames(logCPM_matrix))
rownames(logCPM_matrix) <- expressao
rownames(logCPM_matrix) <- make.names(rownames(logCPM_matrix), unique = TRUE)

test <- rowttests(logCPM_matrix)
ranking <- order(test$p.value)
p_value <- ranking[1:50]
genes_top50 = logCPM_matrix[p_value, ]
```

```{r matriz de distancias}
distxy <- dist(genes_top50, method = 'euclidean')
hc = hclust(distxy, method = 'complete')
plot(hc)
```

```{r}
hcd <- as.dendrogram(hc)
nodePar <- list(lab.cex = 0.6, pch = c(NA,20), cex = 0.8, col = "lightgreen")
plot(hcd, ylab = "Height", nodePar = nodePar, horiz = TRUE, edgePar = list(col = 2:3, lwd = 2:1))
```

Através do clustering hierárquico é possível ver que há uma relação entre os genes sendo possível agrupá-los em alguns clusteres.

```{r}
heatmap(genes_top50, labCol = sort(metadados$SEX))
```

O heatmap não revela nenhum padrão de expressão génica entre homens e mulheres, não havendo o agrupamento de genes em dois clusteres associados ao sexo.

## Clustering de genes de acordo com a sobrevivência dos pacientes

```{r}
heatmap(genes_top50, labCol = sort(metadados$OS_STATUS))
```

Através da análise do heatmap não se consegue distinguir padrões ou clusteres para a sobrevivência dos pacientes baseado na expressão génica.

```{r}
set.seed(123)
logCPM_matrix <- logCPM_matrix[1:length(metadados$OS_STATUS)]
centers <- cut(logCPM_matrix, breaks = 4)
centers_factor <- factor(centers)
live_factor <- factor(metadados$OS_STATUS)

levels(centers_factor) <- c("Cluster 1", "Cluster 2", "Cluster 3", "Cluster 4")

table <- table(centers_factor, live_factor)
print(table)
```

Em contraste, ao distribuir os genes em diferentes clusteres tendo em conta o estado de sobrevivência dos pacientes, obtivémos resultados que sugerem que os genes nos diferentes clusters podem estar envolvidos em diferentes processos biológicos dado que há uma distribuição diferente dos genes pelos 4 clusteres. É interessante destacar que há um nº mais elevado de genes no Cluster 2, o que pode indicar uma possível associação destes com algum processo biológico mais importante para a sobrevivência do que os genes nos outros clusters. 

# **Redução da dimensionalidade**

A análise não supervisionada será aplicada nos dados de expressão genética filtrados para os genes que apenas tenham pelo menos metade dos pacientes com CPM superior a 1 fossem analisados, e normalizado (`logCPM`). 

## Processamento dos dados: 
```{r}
# União dos dados com metadados relevantes para análises:
row.names(metadados) <- metadados$SAMPLE_ID
metadados_select = metadados[,c("SAMPLE_SITE", "OS_STATUS", "CUMULATIVE_TREATMENT_STAGE_COUNT", "CUMULATIVE_TREATMENT_TYPE_COUNT", "ELN_2017", "ELN_2008")]
merged_df <- merge(DADOS, metadados_select, by = "row.names")
row.names(merged_df) <- merged_df$Row.names
merged_df = merged_df[, -1]

```

## Determinação das métricas (PCA)

```{r}
# Formulação do PCA dos dados:
dados_pca = merged_df[, -c(14406:14411)]
pca_result <- prcomp(dados_pca, scale = F)

summary(pca_result)

biplot(pca_result)
```



```{r}
#Visualizar a distribuição dos pontos no PC1 e o PC2:
pca_data <- as.data.frame(pca_result$x[, 1:2])
plot(pca_data$PC1, pca_data$PC2,
     main = "Projeção nos Dois Primeiros Componentes Principais",
     xlab = "PC1",
     ylab = "PC2",
     pch = 19,  
     col = "blue") 

# determinação de qunatos PCAs explicam 90% dos dados:
prop_var <- summary(pca_result)$importance["Proportion of Variance",]
cumulative_prop_var <- cumsum(prop_var)
n_components_90 <- which(cumulative_prop_var >= 0.9)[1]
n_components_90 
```

A análise dos dados a partir de PCA permitiu concluir que os primeiros 132 componentes principais explicam 90% da variabilidade dos dados, como esse número é consideravelmente inferior ao número inicial de genes (14405), é possível fazer uma redução da dimensão sem perder muita informação. Posteriormente, essa informação pode ser usada para seleccionar os genes que mais contribuem para a variabilidade dos dados de expressão e identificar os processos biológicos significativos.


```{r}
# Análise da qualidade das variáveis individuais nos dois primeiros componentes principais
fviz_famd_ind(pca_result, geom = c("point"), col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), palette = "rainbow", addEllipses = FALSE, ellipse.type = "confidence",ggtheme = theme_minimal(), repel = TRUE, labels = F)  

```

No gráfico `Individual-PCA` é possível observar a qualidade da representação ("cos2") das variáveis individuais nos dois primeiros componentes principais (que em conjunto explicam 28,1% da variabilidade dos dados), assim nota-se que as variáveis mais próximas de zero, apresentam uma variação menos explicada do que as mais distantes (coloração alaranjada). 

### Análise de diferentes metadados e suas distribuições nos PCAs

```{r}
# Análise dos dados para diferentes metadados:
# Sample_site:
autoplot(pca_result, data = as.data.frame(merged_df), colour = 'SAMPLE_SITE', size = 2, main = "SAMPLE_SITE")

# Plotegem de um gréfico com 3 dimensões
pca_data <- pca_result$x[, 1:3]
scatterplot3d(pca_data, color = as.integer(merged_df$SAMPLE_SITE), pch = 16,
              xlab = "PC1", ylab = "PC2", zlab = "PC3", main = "Representação de 3 dimensões - SAMPLE_SITE")

# "CUMULATIVE_TREATMENT_STAGE_COUNT"
autoplot(pca_result, data = as.data.frame(merged_df), colour = "CUMULATIVE_TREATMENT_STAGE_COUNT", size = 2, main = "CUMULATIVE_TREATMENT_STAGE_COUNT")

# "CUMULATIVE_TREATMENT_TYPE_COUNT"
autoplot(pca_result, data = as.data.frame(merged_df), colour = "CUMULATIVE_TREATMENT_TYPE_COUNT", size = 2, main = "CUMULATIVE_TREATMENT_TYPE_COUNT")

# "OS_STATUS"
legenda_personalizada <- c("No inf" = "gray", "0:LIVING" = "red", "1:DECEASED" = "green")
autoplot(pca_result, data = as.data.frame(merged_df), colour = "OS_STATUS", size = 2, main = "OS_STATUS") +
  scale_color_manual(values = legenda_personalizada) # Cinza são os NAs. 

scatterplot3d(pca_data, color = as.integer(merged_df$OS_STATUS), pch = 16,
              xlab = "PC1", ylab = "PC2", zlab = "PC3", main = "Representação de 3 dimensões - OS_STATUS")

# "ELN_2008"
autoplot(pca_result, data = as.data.frame(merged_df), colour = 'ELN_2008', size = 2, main = "ELN_2008")
pca_data <- pca_result$x[, 1:3]
scatterplot3d(pca_data, color = as.integer(merged_df$SAMPLE_SITE), pch = 16,
              xlab = "PC1", ylab = "PC2", zlab = "PC3", main = "Representação de 3 dimensões- pca_data  <- ELN_2008")

# "ELN_2017"
autoplot(pca_result, data = as.data.frame(merged_df), colour = 'ELN_2017', size = 2, main = "ELN_2017")
pca_data <- pca_result$x[, 1:3]
scatterplot3d(pca_data, color = as.integer(merged_df$SAMPLE_SITE), pch = 16,
              xlab = "PC1", ylab = "PC2", zlab = "PC3", main = "Representação de 3 dimensões- pca_data  <- ELN_2017")
```
A observação dos diferentes PCAs foi determinada para diferentes categorias dos metadados, de forma a tentar visualizar se há separação entre os diferentes fatores. É possível concluir que não há agrupamento notável ente os diferentes grupos das variáveis analisada: `Sample_site`, `CUMULATIVE_TREATMENT_STAGE_COUNT`, `CUMULATIVE_TREATMENT_TYPE_COUNT`, `OS_STATUS`, `ELN_2008` e `ELN_2017`. 
É importante ressaltar que esta observação foi realizada apenas até o terceiro Componente Principal, o qual explica conjuntamente cerca de 34,5% da variação nos dados. Portanto, é possível que a variação entre diferentes grupos de amostras não esteja completamente representada nesses primeiros componentes. Futuras análises podem explorar componentes adicionais para uma compreensão mais completa da estrutura dos dados e a identificação de possíveis padrões de agrupamento.

# **Machine Learning**

## Preparação do modelo

Iremos utilizar o dataset "merged_df", adicionando ainda algumas colunas de metadados que possam ter relevancia na análise, e removendo outras que não têm! Além disso, fazemos também algumas alterações ao nome das variáveis. Em todos os modelos foi utilizada uma estimação do erro corresponde a validação cruzada com 10 folds repetida 5 vezes, aquando da sua construção. De forma a tornar estes resultados replicáveis, foi invocada uma seed de valor “9999”.

```{r Preparação dos dados - treino}

# Definir a seed para caso se queira reproduzir estes resultados

set.seed(9999)

cvcontrol = trainControl( method = 'repeatedcv', number = 10, repeats = 5)


# Criámos uma nova variável que representa os dados que serão utilizados no ML

ml_data = merged_df

# Removemos colunas que não importavam

ml_data <- ml_data[, !(colnames(ml_data) %in% c("OS_STATUS", "SAMPLE_SITE", "CUMULATIVE_TREATMENT_STAGE_COUNT", "CUMULATIVE_TREATMENT_TYPE_COUNT"))]

# Adicionámos as colunas que queremos analisar

ml_data$ELN_2017 <- metadados[rownames(ml_data), "ELN_2017"]

ml_data$ELN_2008 <- data_sample[rownames(ml_data), "ELN_2008"]

# Vamos verficar quantos elementos possui cada variável 
#table(ml_data$ELN_2017)
#table(ml_data$ELN_2008)

# O Unknown apresenta apenas 1 elemento e será melhor removê-lo
ml_data <- ml_data[ml_data$ELN_2017 != "Unknown", ]

# Além disso, valores como "Intermediate I e II" devem ser transformados em apenas "Intermediate"
ml_data$ELN_2008 <- gsub("Intermediate-?I+", "Intermediate", ml_data$ELN_2008, ignore.case = TRUE)


# Fazer o mesmo com o ELN_2017
ml_data$ELN_2017 <- gsub("Intermediate or Adverse", "Intermediate", ml_data$ELN_2017, ignore.case = TRUE)
ml_data$ELN_2017 <- gsub("Favorable or Intermediate", "Intermediate", ml_data$ELN_2017, ignore.case = TRUE)


table(ml_data$ELN_2008)
table(ml_data$ELN_2017)


# Passar para fator
ml_data$ELN_2017 <- as.factor(ml_data$ELN_2017)
ml_data$ELN_2008 <- as.factor(ml_data$ELN_2008)


#Removemos também valores omissos e espaços em branco

ml_data$ELN_2017[ml_data$ELN_2017 == ""] <- NA
ml_data$ELN_2008[ml_data$ELN_2008 == ""] <- NA

ml_data <- na.omit(ml_data)


```


Após preparar os dados, fizemos a divisão dos entre dados para treinar o modelo (70%), e dados para o testar (30%).

```{r Preparação dos modelos}

# Dividir os dados em conjuntos de treino e teste (70% treino, 30% teste)

# Para o ELN_2017
indices_2017 <- createDataPartition(ml_data$ELN_2017, p = 0.7, list = FALSE)

dados_treino_2017 <- ml_data[indices_2017, ]
dados_teste_2017 <- ml_data[-indices_2017, ]


# Para o ELN_2008
indices_2008 <- createDataPartition(ml_data$ELN_2008, p = 0.7, list = FALSE)
dados_treino_2008 <- ml_data[indices_2008, ]
dados_teste_2008 <- ml_data[-indices_2008, ]


```

Agora, podemos passar à aplicação de diferentes modelos.


## Árvore de decisão

Primeiramente, procedemos ao treino do modelo com os dados selecionados previamente. 

```{r Árvore de Decisão - ENL_2017}


# Definir o modelo
modelo_dt_2017 = ctree(ELN_2017 ~ ., data = dados_treino_2017)

# Visualizar o modelo
print(modelo_dt_2017)

```


```{r Árvore de Decisão - ENL_2008}

# Definir o modelo
modelo_dt_2008 = ctree(ELN_2008 ~ ., data = dados_treino_2008)

# Visualizar o modelo
print(modelo_dt_2008)

```


Depois fizemos um plot da árvore de decisão relativa aos dados de teste.


```{r Árvores de Decisão ENL_2017 - Plot}

plot(modelo_dt_2017)

```

```{r Árvores de Decisão ENL_2008 - Plot}

plot(modelo_dt_2008)

```


Depois do treino, devemos avaliar a sua performance. Para isso, primeiramente é necessário testar o modelo!


```{r - DT_2017 Teste}

testDT_2017 = predict(modelo_dt_2017, dados_teste_2017)

```


```{r - DT_2008 Teste}

testDT_2008 = predict(modelo_dt_2008, dados_teste_2008)

```


Após o teste, criamos uma tabela comparando os resultados obtidos e os resultados esperados, e calculamos a precisão do modelo


```{r DT_2017 - Avaliação do modelo}

# Comparação dos resultados utilizando uma tabela

table(testDT_2017, dados_teste_2017$ELN_2017)


# Calculo da precisão

precisao_DT_2017 = mean(testDT_2017 == dados_teste_2017$ELN_2017)
precisao_DT_2017
```

```{r DT_2008 - Avaliação do modelo}

table(testDT_2008, dados_teste_2008$ELN_2008)

precisao_DT_2008 = mean(testDT_2008 == dados_teste_2008$ELN_2008)
precisao_DT_2008
```

É possível observar que com o modelo de Árvores de decisão, obteve-se uma precisão de aproximadamente 58% para o ENL_2017 e de 51% para o ENL_2008. Esses valores representam percentagens de acerto bastante baixas, o que pode significar algum tipo de problema. Esse problema pode ir desde o overfitting, quantidade pequena de dados, dados muito simples e com uma separação clara entre eles, o algoritmo utilizado pode ser inadequado ou os parâmetros podem estar mal ajustados.



## Naive-Bayes

Utilizando os dados de teste e dados de treino definidos anteriormente, realizou-se o treino e o teste do modelo Naive-Bayes.

```{r Naive-Bayes - ENL_2017}

modelo_nb_2017 = naiveBayes(ELN_2017 ~ ., data = dados_treino_2017)

testeNB_2017 = predict(modelo_nb_2017, dados_teste_2017)

```

```{r Naive-Bayes - ENL_2008}

modelo_nb_2008 = naiveBayes(ELN_2008 ~ ., data = dados_treino_2008)

testeNB_2008 = predict(modelo_nb_2008, dados_teste_2008)

```


Após os testes, procedeu-se à análise dos seus resultados utilizando uma tabela e calculando a sua precisão.

```{r NB_2017 - Avaliação}

table(testeNB_2017, dados_teste_2017$ELN_2017)

precisao_NB_2017 = mean(testeNB_2017 == dados_teste_2017$ELN_2017)

precisao_NB_2017
```

```{r NB_2008 - Avaliação}

table(testeNB_2008, dados_teste_2008$ELN_2008)

precisao_NB_2008 = mean(testeNB_2008 == dados_teste_2008$ELN_2008)

precisao_NB_2008
```

Na tabela obtida, é possível verificar bastantes missmatches entre os valores previstos pelo modelo e os valores reais. Calculando a sua precisão, verificou-se uma precisão de 46% para a previsão do ELN_2017 e 56% para a previsão do ELN_2008, valores ligeiramente mais baixos que o modelo anterior, podendo significar uma aleatoriedade do modelo criado. Isso pode acontecer devido a um mau tratamento de dados, má escolha de classes, ou mau uso dos hiperparâmetros. De qualquer forma, também não é um resultado satisfatório para a previsão dos nossos dados.

## Importância de genes:

```{r}
set.seed(16718)
dados_treino_2017 <- na.omit(dados_treino_2017)
dados_teste_2017 <- na.omit(dados_teste_2017)

# Configurar o controle para RFE
control <- rfeControl(functions = rfFuncs, method = "cv", number = 10)

# Executar o RFE
results <- rfe(dados_treino_2017[ , !names(dados_treino_2017) %in% c("ELN_2017")], dados_treino_2017$ELN_2017, 
               rfeControl = control, sizes = c(1:10, 20, 40, 60, 80, 100))

# Obter as variáveis mais importantes
important_vars <- predictors(results)
print(important_vars)
```




